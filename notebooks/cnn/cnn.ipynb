{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_jotgRwPJ66"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "from keras.utils import layer_utils, np_utils\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgtcRhtzT77L"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "RESCALE_POND = 255\n",
        "PATH_MAIN = os.path.abspath(os.path.join(\"../..\"))\n",
        "PATH_DRIVE = os.path.join(PATH_MAIN,\"data\",\"grapes images\")\n",
        "PATH_TRAIN = os.path.join(PATH_DRIVE, \"train\")\n",
        "PATH_TEST = os.path.join(PATH_DRIVE, \"validation\")\n",
        "\n",
        "def load_image_from_path(path):\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  images_folders = os.listdir(path)\n",
        "\n",
        "  for folder in images_folders:\n",
        "    print(folder)\n",
        "    images_files_path = os.path.join(path,folder)\n",
        "    images_file_names = os.listdir(images_files_path)\n",
        "\n",
        "    for image_file in images_file_names:\n",
        "      complete_path = os.path.join(images_files_path,image_file)\n",
        "      images =load_img(complete_path, target_size=(IMG_HEIGHT,IMG_WIDTH))\n",
        "      x.append(img_to_array(images))\n",
        "      y.append(folder)\n",
        "\n",
        "  return x,y\n",
        "\n",
        "def load_save_image(path_train,path_test):\n",
        "  x_train, y_train = load_image_from_path(path_train)\n",
        "  # path = os.path.join(PATH_DRIVE,\"x_train_orig.pkl\")\n",
        "  # save_pickle(x_train,path)\n",
        "  # del x_train\n",
        "  # path = os.path.join(PATH_DRIVE,\"y_train_orig.pkl\")\n",
        "  # save_pickle(y_train,path)\n",
        "  # del y_train\n",
        "  x_test,y_test =load_image_from_path(path_test)\n",
        "  # path = os.path.join(PATH_DRIVE,\"x_test_orig.pkl\")\n",
        "  # save_pickle(x_test,path)\n",
        "  # del x_test\n",
        "  # path = os.path.join(PATH_DRIVE,\"y_test_orig.pkl\")\n",
        "  # save_pickle(y_test,path)\n",
        "  # del y_test\n",
        "  return x_train, y_train,x_test,y_test\n",
        "\n",
        "\n",
        "def encode_by_list(label_list, to_encode_list):\n",
        "  encode_list =[label_list.index(item) for item in to_encode_list]\n",
        "  return np_utils.to_categorical(encode_list,len(label_list))\n",
        "\n",
        "def normalize(np_array):\n",
        "  return np_array/RESCALE_POND\n",
        "\n",
        "def save_pickle(object,path):\n",
        "  pickle.dump(object,open(path,'wb'))\n",
        "\n",
        "def load_pickle(filename):\n",
        "  path = os.path.join(PATH_DRIVE,filename)\n",
        "  result=pickle.load(open(path,'rb'))\n",
        "  return result\n",
        "\n",
        "def plot_loss_and_accuracy(model_fitted):\n",
        "  accuracy = model_trained.history['acc']\n",
        "  val_accuracy = model_trained.history['val_acc']\n",
        "  loss = model_trained.history['loss']\n",
        "  val_loss = model_trained.history['val_loss']\n",
        "  epochs = range(len(accuracy))\n",
        "  plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
        "  plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "  plt.ylim(ymin=0)\n",
        "  plt.ylim(ymax=1)\n",
        "  plt.xlabel('Epochs ', fontsize=16)\n",
        "  plt.ylabel('Accuracity', fontsize=16)\n",
        "  plt.title('Training and validation accuracy', fontsize = 20)\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.xlabel('Epochs ', fontsize=16)\n",
        "  plt.ylabel('Loss', fontsize=16)\n",
        "  plt.title('Training and validation loss', fontsize= 20)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDhlfJL_dYZ1",
        "outputId": "a8eecf69-423a-4d25-8960-2605c9523b51"
      },
      "outputs": [],
      "source": [
        "x_train, y_train,x_test,y_test = load_save_image(PATH_TRAIN,PATH_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeRWPGYMq_Zg"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "labels = list(set(y_train))\n",
        "y_train = encode_by_list(labels,y_train)\n",
        "y_train = np.array(y_train)\n",
        "y_test = encode_by_list(labels,y_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = normalize(x_train)\n",
        "x_test =  normalize(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(x_train), len(y_train),len(x_test), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_nn(height,width):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(height,width,3),name=\"Input_layer\"))\n",
        "    model.add(layers.Dense(1000,activation = 'relu', name = \"Hidden_layer_1\"))\n",
        "    model.add(layers.Dense(500,activation = 'relu', name = \"Hidden_layer_2\"))\n",
        "    model.add(layers.Dense(4,activation = 'softmax', name = \"Output_layer\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def simple_cnn(height,width):  \n",
        "  model = models.Sequential()\n",
        "  \n",
        "  model.add(layers.Conv2D(32, kernel_size=(3, 3), input_shape=(height, width, 3), activation='relu'))\n",
        "\n",
        "  model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "  model.add(layers.Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Conv2D(1024, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(500, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snn_model = simple_nn(IMG_HEIGHT,IMG_WIDTH)\n",
        "snn_model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['acc','mse'])\n",
        "snn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "callbacks = [ModelCheckpoint(filepath='weights.{epoch:02d}-val_acc:{val_acc:.2f}.h5', monitor='val_acc', save_best_only=True, verbose=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snn = snn_model.fit(x=x_train, y = y_train, batch_size = 32, epochs= EPOCHS, verbose=1, validation_data=(x_test,y_test), shuffle= True, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model = simple_cnn(IMG_HEIGHT,IMG_WIDTH)\n",
        "cnn_model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['acc','mse'])\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn = cnn_model.fit(x=x_train, y = y_train, batch_size = 32, epochs= EPOCHS, verbose=1, validation_data=(x_test,y_test), shuffle= True,callbacks=callbacks)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMOoJYxq0T2i3KIm47KWspP",
      "mount_file_id": "https://github.com/javapagar/KG_applied_to_ML/blob/main/notebooks/cnn/cnn.ipynb",
      "name": "CNN.pynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
